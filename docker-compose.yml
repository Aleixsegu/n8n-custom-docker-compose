services:
  n8n:
    build:
      context: ./n8n
      dockerfile: Dockerfile
    container_name: n8n
    restart: unless-stopped
    ports:
      - "5678:5678"
    environment:
      - N8N_HOST=localhost
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - WEBHOOK_URL=http://localhost:5678/
      - GENERIC_TIMEZONE=Europe/Madrid
      - NODE_ENV=production
      - EXECUTIONS_DATA_PRUNE=true
      - NODE_FUNCTION_ALLOW_BUILTIN=fs,path,crypto
      - N8N_BLOCK_FILE_ACCESS_TO_N8N_FILES=false
      - N8N_RESTRICT_FILE_ACCESS_TO=/downloads
    volumes:
      - n8n_data:/home/node/.n8n
      - ytdlp_downloads:/downloads:ro

  whisper:
    build:
      context: ./whisper
      dockerfile: Dockerfile
    container_name: whisper
    restart: unless-stopped
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - whisper_cache:/root/.cache
      - whisper_models:/root/.cache/whisper

  ytdlp:
    build:
      context: ./ytdlp
      dockerfile: Dockerfile
    container_name: ytdlp
    restart: unless-stopped
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - ytdlp_downloads:/downloads
      - ytdlp_cache:/root/.cache

  llama:
    build:
      context: ./llama
      dockerfile: Dockerfile
    container_name: llama
    restart: unless-stopped
    ports:
      - "8083:8083"
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - llama_models:/root/.cache/huggingface

volumes:
  n8n_data:
  whisper_cache:
  whisper_models:
  ytdlp_downloads:
  ytdlp_cache:
  llama_models:
